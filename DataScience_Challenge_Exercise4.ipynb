{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation of the pandas library \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   act_date             10000 non-null  object\n",
      " 1   source               10000 non-null  object\n",
      " 2   pos_ctry             10000 non-null  object\n",
      " 3   pos_iata             10000 non-null  object\n",
      " 4   pos_oid              10000 non-null  object\n",
      " 5   rloc                 10000 non-null  object\n",
      " 6   cre_date             10000 non-null  object\n",
      " 7   duration             10000 non-null  int64 \n",
      " 8   distance             10000 non-null  int64 \n",
      " 9   dep_port             10000 non-null  object\n",
      " 10  dep_city             10000 non-null  object\n",
      " 11  dep_ctry             10000 non-null  object\n",
      " 12  arr_port             10000 non-null  object\n",
      " 13  arr_city             10000 non-null  object\n",
      " 14  arr_ctry             10000 non-null  object\n",
      " 15  lst_port             10000 non-null  object\n",
      " 16  lst_city             10000 non-null  object\n",
      " 17  lst_ctry             10000 non-null  object\n",
      " 18  brd_port             10000 non-null  object\n",
      " 19  brd_city             10000 non-null  object\n",
      " 20  brd_ctry             10000 non-null  object\n",
      " 21  off_port             10000 non-null  object\n",
      " 22  off_city             10000 non-null  object\n",
      " 23  off_ctry             10000 non-null  object\n",
      " 24  mkt_port             10000 non-null  object\n",
      " 25  mkt_city             10000 non-null  object\n",
      " 26  mkt_ctry             10000 non-null  object\n",
      " 27  intl                 10000 non-null  int64 \n",
      " 28  route                10000 non-null  object\n",
      " 29  carrier              10000 non-null  object\n",
      " 30  bkg_class            10000 non-null  object\n",
      " 31  cab_class            10000 non-null  object\n",
      " 32  brd_time             10000 non-null  object\n",
      " 33  off_time             10000 non-null  object\n",
      " 34  pax                  10000 non-null  int64 \n",
      " 35  year                 10000 non-null  int64 \n",
      " 36  month                10000 non-null  int64 \n",
      " 37  oid                  10000 non-null  object\n",
      "dtypes: int64(6), object(32)\n",
      "memory usage: 2.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 45 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Date               10000 non-null  object\n",
      " 1   Time               10000 non-null  object\n",
      " 2   TxnCode            10000 non-null  object\n",
      " 3   OfficeID           10000 non-null  object\n",
      " 4   Country            10000 non-null  object\n",
      " 5   Origin             10000 non-null  object\n",
      " 6   Destination        10000 non-null  object\n",
      " 7   RoundTrip          10000 non-null  int64 \n",
      " 8   NbSegments         10000 non-null  int64 \n",
      " 9   Seg1Departure      10000 non-null  object\n",
      " 10  Seg1Arrival        10000 non-null  object\n",
      " 11  Seg1Date           9973 non-null   object\n",
      " 12  Seg1Carrier        4047 non-null   object\n",
      " 13  Seg1BookingCode    1143 non-null   object\n",
      " 14  Seg2Departure      7196 non-null   object\n",
      " 15  Seg2Arrival        7196 non-null   object\n",
      " 16  Seg2Date           7161 non-null   object\n",
      " 17  Seg2Carrier        2870 non-null   object\n",
      " 18  Seg2BookingCode    998 non-null    object\n",
      " 19  Seg3Departure      534 non-null    object\n",
      " 20  Seg3Arrival        534 non-null    object\n",
      " 21  Seg3Date           531 non-null    object\n",
      " 22  Seg3Carrier        517 non-null    object\n",
      " 23  Seg3BookingCode    508 non-null    object\n",
      " 24  Seg4Departure      440 non-null    object\n",
      " 25  Seg4Arrival        440 non-null    object\n",
      " 26  Seg4Date           439 non-null    object\n",
      " 27  Seg4Carrier        438 non-null    object\n",
      " 28  Seg4BookingCode    436 non-null    object\n",
      " 29  Seg5Departure      103 non-null    object\n",
      " 30  Seg5Arrival        103 non-null    object\n",
      " 31  Seg5Date           103 non-null    object\n",
      " 32  Seg5Carrier        103 non-null    object\n",
      " 33  Seg5BookingCode    103 non-null    object\n",
      " 34  Seg6Departure      58 non-null     object\n",
      " 35  Seg6Arrival        58 non-null     object\n",
      " 36  Seg6Date           58 non-null     object\n",
      " 37  Seg6Carrier        58 non-null     object\n",
      " 38  Seg6BookingCode    58 non-null     object\n",
      " 39  From               9925 non-null   object\n",
      " 40  IsPublishedForNeg  10000 non-null  int64 \n",
      " 41  IsFromInternet     10000 non-null  int64 \n",
      " 42  IsFromVista        10000 non-null  int64 \n",
      " 43  TerminalID         10000 non-null  object\n",
      " 44  InternetOffice     10000 non-null  object\n",
      "dtypes: int64(5), object(40)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "\n",
    "#bookings\n",
    "\n",
    "df_bookings = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^')\n",
    "\n",
    "bookings_head20 = df_bookings.head(20)\n",
    "bookings_info = df_bookings.info()\n",
    "bookings_columns = df_bookings.columns\n",
    "\n",
    "#searches\n",
    "\n",
    "df_searches = pd.read_csv(\"searches.csv.bz2\", compression='bz2', nrows = 10000, sep = '^')\n",
    "searches_head20 = df_searches.head(20)\n",
    "searches_info = df_searches.info()\n",
    "searches_columns = df_searches.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the fields that are in both datasets to check by which labels we will pair up:\n",
    "\n",
    "    a) Origin and destination airports already suggested in the wording of the exercise.\n",
    "    \n",
    "    b) Same day : cre_date(bookings) and Date(searches).\n",
    "    \n",
    "    c) I will keep the Seg1BookingCode from the researches dataset in case it's useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act_date           ', 'source', 'pos_ctry', 'pos_iata', 'pos_oid  ',\n",
       "       'rloc          ', 'cre_date           ', 'duration', 'distance',\n",
       "       'dep_port', 'dep_city', 'dep_ctry', 'arr_port', 'arr_city', 'arr_ctry',\n",
       "       'lst_port', 'lst_city', 'lst_ctry', 'brd_port', 'brd_city', 'brd_ctry',\n",
       "       'off_port', 'off_city', 'off_ctry', 'mkt_port', 'mkt_city', 'mkt_ctry',\n",
       "       'intl', 'route          ', 'carrier', 'bkg_class', 'cab_class',\n",
       "       'brd_time           ', 'off_time           ', 'pax', 'year', 'month',\n",
       "       'oid      '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bookings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Booking dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_date</th>\n",
       "      <th>cre_date</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>arr_port</th>\n",
       "      <th>brd_time</th>\n",
       "      <th>off_time</th>\n",
       "      <th>oid</th>\n",
       "      <th>CommonKey</th>\n",
       "      <th>Counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>LHR</td>\n",
       "      <td>2013-03-07 08:50:00</td>\n",
       "      <td>2013-03-07 11:33:37</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2013-03-05 ZRH LHR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>SAL</td>\n",
       "      <td>CLT</td>\n",
       "      <td>2013-04-12 13:04:00</td>\n",
       "      <td>2013-04-12 22:05:40</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2013-03-26 SAL CLT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>SAL</td>\n",
       "      <td>CLT</td>\n",
       "      <td>2013-07-15 07:00:00</td>\n",
       "      <td>2013-07-15 11:34:51</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2013-03-26 SAL CLT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>AKL</td>\n",
       "      <td>SVO</td>\n",
       "      <td>2013-04-24 23:59:00</td>\n",
       "      <td>2013-04-25 16:06:31</td>\n",
       "      <td>SYDA82546</td>\n",
       "      <td>2013-03-26 AKL SVO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>AKL</td>\n",
       "      <td>SVO</td>\n",
       "      <td>2013-05-14 20:15:00</td>\n",
       "      <td>2013-05-16 10:44:50</td>\n",
       "      <td>SYDA82546</td>\n",
       "      <td>2013-03-26 AKL SVO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    act_date   cre_date dep_port arr_port            brd_time  \\\n",
       "0 2013-03-05 2013-02-22      ZRH      LHR 2013-03-07 08:50:00   \n",
       "1 2013-03-26 2013-03-26      SAL      CLT 2013-04-12 13:04:00   \n",
       "2 2013-03-26 2013-03-26      SAL      CLT 2013-07-15 07:00:00   \n",
       "3 2013-03-26 2013-03-26      AKL      SVO 2013-04-24 23:59:00   \n",
       "4 2013-03-26 2013-03-26      AKL      SVO 2013-05-14 20:15:00   \n",
       "\n",
       "             off_time        oid           CommonKey  Counter  \n",
       "0 2013-03-07 11:33:37  NULL       2013-03-05 ZRH LHR        1  \n",
       "1 2013-04-12 22:05:40  NULL       2013-03-26 SAL CLT        1  \n",
       "2 2013-07-15 11:34:51  NULL       2013-03-26 SAL CLT        1  \n",
       "3 2013-04-25 16:06:31  SYDA82546  2013-03-26 AKL SVO        1  \n",
       "4 2013-05-16 10:44:50  SYDA82546  2013-03-26 AKL SVO        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing only the key data\n",
    "\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 5, sep = '^')\n",
    "filecolumns = file.columns\n",
    "\n",
    "#Create a list with the headers without empty spaces\n",
    "\n",
    "list_columns = list(filecolumns)\n",
    "fixed_columns = []\n",
    "for col in list_columns:\n",
    "    fixed_columns.append(col.strip())\n",
    "\n",
    "cols = ['act_date','cre_date','dep_port','arr_port','brd_time','off_time','oid']\n",
    "df_bookings = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^', skiprows = 1, usecols = cols, names = fixed_columns, parse_dates = ['act_date','cre_date','brd_time','off_time'])\n",
    "\n",
    "    # cleaning dataset empty spaces\n",
    "for i, r in enumerate(df_bookings['arr_port']):  \n",
    "    r1 = r.strip()\n",
    "    df_bookings.at[i, 'arr_port'] = r1\n",
    "    \n",
    "for i, r in enumerate(df_bookings['dep_port']):  \n",
    "    r1 = r.strip()\n",
    "    df_bookings.at[i, 'dep_port'] = r1\n",
    "    \n",
    "df_bookings['CommonKey'] = df_bookings['act_date'].astype(str) + ' ' + df_bookings['dep_port'] + ' ' + df_bookings['arr_port'] # Creation of a common key as a column\n",
    "df_bookings['Counter'] = 1\n",
    "df_bookings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Searches dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Seg1BookingCode</th>\n",
       "      <th>CommonKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 TXL AUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 ATH MIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 ICT SFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>W</td>\n",
       "      <td>2013-01-01 RNB ARN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 OSL MAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Origin Destination Seg1BookingCode           CommonKey\n",
       "0 2013-01-01    TXL         AUH             NaN  2013-01-01 TXL AUH\n",
       "1 2013-01-01    ATH         MIL             NaN  2013-01-01 ATH MIL\n",
       "2 2013-01-01    ICT         SFO             NaN  2013-01-01 ICT SFO\n",
       "3 2013-01-01    RNB         ARN               W  2013-01-01 RNB ARN\n",
       "4 2013-01-01    OSL         MAD             NaN  2013-01-01 OSL MAD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing only the key data\n",
    "\n",
    "col_searches = ['Date','Origin','Destination','Seg1BookingCode']\n",
    "df_searches = pd.read_csv(\"searches.csv.bz2\", compression='bz2', nrows = 10000, sep = '^', usecols = col_searches, parse_dates = ['Date'])\n",
    "df_searches['CommonKey'] = df_searches['Date'].astype(str) + ' ' + df_searches['Origin'] + ' ' + df_searches['Destination'] # Creation of a common key as a column\n",
    "df_searches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the merge of both datasets: I will work with two small databases to check that will work. So that :\n",
    "\n",
    "    a) I will select the first 10K rows from both databases\n",
    "    b) To simplify I will consider that only Origin and Destination airports are the fields to check if a search ends up with a booking ( Date will be needed when I work with the complete databases)\n",
    "    c) From searches I will pick only ones where Origin = LAX\n",
    "    d) From bookings I will select only yhe ones where Origin = LAX and Destination = CDG\n",
    "    e) I must have the original searches dataset indicating when Origin = LAX and Destination = CDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Seg1BookingCode</th>\n",
       "      <th>CommonKey</th>\n",
       "      <th>CommonKey2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LAX</td>\n",
       "      <td>BJX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 LAX BJX</td>\n",
       "      <td>LAX BJX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 LAX CDG</td>\n",
       "      <td>LAX CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 LAX MEL</td>\n",
       "      <td>LAX MEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LAX</td>\n",
       "      <td>TLV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 LAX TLV</td>\n",
       "      <td>LAX TLV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MEX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 LAX MEX</td>\n",
       "      <td>LAX MEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MEX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-10 LAX MEX</td>\n",
       "      <td>LAX MEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>LAX</td>\n",
       "      <td>DXB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-10 LAX DXB</td>\n",
       "      <td>LAX DXB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9808</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SAL</td>\n",
       "      <td>C</td>\n",
       "      <td>2013-01-10 LAX SAL</td>\n",
       "      <td>LAX SAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>LAX</td>\n",
       "      <td>LHR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-10 LAX LHR</td>\n",
       "      <td>LAX LHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9852</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>LAX</td>\n",
       "      <td>BER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-10 LAX BER</td>\n",
       "      <td>LAX BER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Origin Destination Seg1BookingCode           CommonKey  \\\n",
       "174  2013-01-01    LAX         BJX             NaN  2013-01-01 LAX BJX   \n",
       "286  2013-01-01    LAX         CDG             NaN  2013-01-01 LAX CDG   \n",
       "372  2013-01-01    LAX         MEL             NaN  2013-01-01 LAX MEL   \n",
       "386  2013-01-01    LAX         TLV             NaN  2013-01-01 LAX TLV   \n",
       "438  2013-01-01    LAX         MEX             NaN  2013-01-01 LAX MEX   \n",
       "...         ...    ...         ...             ...                 ...   \n",
       "9754 2013-01-10    LAX         MEX             NaN  2013-01-10 LAX MEX   \n",
       "9775 2013-01-10    LAX         DXB             NaN  2013-01-10 LAX DXB   \n",
       "9808 2013-01-10    LAX         SAL               C  2013-01-10 LAX SAL   \n",
       "9834 2013-01-10    LAX         LHR             NaN  2013-01-10 LAX LHR   \n",
       "9852 2013-01-10    LAX         BER             NaN  2013-01-10 LAX BER   \n",
       "\n",
       "     CommonKey2  \n",
       "174     LAX BJX  \n",
       "286     LAX CDG  \n",
       "372     LAX MEL  \n",
       "386     LAX TLV  \n",
       "438     LAX MEX  \n",
       "...         ...  \n",
       "9754    LAX MEX  \n",
       "9775    LAX DXB  \n",
       "9808    LAX SAL  \n",
       "9834    LAX LHR  \n",
       "9852    LAX BER  \n",
       "\n",
       "[139 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection of the 10K first rows filtering by Origin : LAX ---> I REFUSED THE IDEA OF CREATING A COMMONKEY!!!!\n",
    "\n",
    "df_searches['CommonKey2'] = df_searches['Origin'] + ' ' + df_searches['Destination']\n",
    "test_searches = df_searches[(df_searches['Origin'] == 'LAX')]\n",
    "test_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommonKey2</th>\n",
       "      <th>Counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAX CDG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CommonKey2  Counter\n",
       "0    LAX CDG        4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection of the 10K first rows filtering by Origin : LAX and Destination: GDG\n",
    "\n",
    "df_bookings['CommonKey2'] = df_bookings['dep_port'] + ' ' + df_bookings['arr_port']\n",
    "test_bookings = df_bookings[(df_bookings['dep_port'] == 'LAX') & (df_bookings['arr_port'] == 'CDG')]\n",
    "test_bookings = test_bookings.groupby('CommonKey2')['Counter'].sum().reset_index()\n",
    "test_bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update searches dataframe ( Origin = LAX) with booking dataframe ( Origin = LAX & Destination = CGD)\n",
    "\n",
    "# If it works I will get a 139 rows dataframe with a new Column Counter that will be 1 when Destination = CDG\n",
    "\n",
    "test_result = test_searches.merge(test_bookings,how='left', on ='CommonKey2',indicator = False)\n",
    "test_result['Counter'] = test_result['Counter']/test_result['Counter']\n",
    "test_result['Counter'] = test_result['Counter'].fillna(0)\n",
    "test_result.Counter.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I am getting a 139 rows dataframe. But this time with the additional Column 'Counter' that will be different to zero when matches up with the bookings dataframe. The total matches is equal to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Seg1BookingCode</th>\n",
       "      <th>CommonKey</th>\n",
       "      <th>CommonKey2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 LAX CDG</td>\n",
       "      <td>LAX CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-07 LAX CDG</td>\n",
       "      <td>LAX CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9669</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-10 LAX CDG</td>\n",
       "      <td>LAX CDG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Origin Destination Seg1BookingCode           CommonKey  \\\n",
       "286  2013-01-01    LAX         CDG             NaN  2013-01-01 LAX CDG   \n",
       "6119 2013-01-07    LAX         CDG             NaN  2013-01-07 LAX CDG   \n",
       "9669 2013-01-10    LAX         CDG             NaN  2013-01-10 LAX CDG   \n",
       "\n",
       "     CommonKey2  \n",
       "286     LAX CDG  \n",
       "6119    LAX CDG  \n",
       "9669    LAX CDG  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_searches['CommonKey2'] = df_searches['Origin'] + ' ' + test_searches['Destination']\n",
    "test_searches = df_searches[(df_searches['Origin'] == 'LAX') & (df_searches['Destination'] == 'CDG')]\n",
    "test_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looks like it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating the solution of the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fixed booking headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 5, sep = '^')\n",
    "filecolumns = file.columns\n",
    "\n",
    "#Create a list with the headers without empty spaces\n",
    "\n",
    "list_columns = list(filecolumns)\n",
    "fixed_columns = []\n",
    "for col in list_columns:\n",
    "    fixed_columns.append(col.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act_date',\n",
       " 'source',\n",
       " 'pos_ctry',\n",
       " 'pos_iata',\n",
       " 'pos_oid',\n",
       " 'rloc',\n",
       " 'cre_date',\n",
       " 'duration',\n",
       " 'distance',\n",
       " 'dep_port',\n",
       " 'dep_city',\n",
       " 'dep_ctry',\n",
       " 'arr_port',\n",
       " 'arr_city',\n",
       " 'arr_ctry',\n",
       " 'lst_port',\n",
       " 'lst_city',\n",
       " 'lst_ctry',\n",
       " 'brd_port',\n",
       " 'brd_city',\n",
       " 'brd_ctry',\n",
       " 'off_port',\n",
       " 'off_city',\n",
       " 'off_ctry',\n",
       " 'mkt_port',\n",
       " 'mkt_city',\n",
       " 'mkt_ctry',\n",
       " 'intl',\n",
       " 'route',\n",
       " 'carrier',\n",
       " 'bkg_class',\n",
       " 'cab_class',\n",
       " 'brd_time',\n",
       " 'off_time',\n",
       " 'pax',\n",
       " 'year',\n",
       " 'month',\n",
       " 'oid']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simplified booking dataset ( 1 unique line x date x origin x destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated lines proccesed: 500000 ( Number of chunks: 1)\n",
      "Accumulated lines proccesed: 1000000 ( Number of chunks: 2)\n",
      "Accumulated lines proccesed: 1500000 ( Number of chunks: 3)\n",
      "Accumulated lines proccesed: 2000000 ( Number of chunks: 4)\n",
      "Accumulated lines proccesed: 2500000 ( Number of chunks: 5)\n",
      "Accumulated lines proccesed: 3000000 ( Number of chunks: 6)\n",
      "Accumulated lines proccesed: 3500000 ( Number of chunks: 7)\n",
      "Accumulated lines proccesed: 4000000 ( Number of chunks: 8)\n",
      "Accumulated lines proccesed: 4500000 ( Number of chunks: 9)\n",
      "Accumulated lines proccesed: 5000000 ( Number of chunks: 10)\n",
      "Accumulated lines proccesed: 5500000 ( Number of chunks: 11)\n",
      "Accumulated lines proccesed: 6000000 ( Number of chunks: 12)\n",
      "Accumulated lines proccesed: 6500000 ( Number of chunks: 13)\n",
      "Accumulated lines proccesed: 7000000 ( Number of chunks: 14)\n",
      "Accumulated lines proccesed: 7500000 ( Number of chunks: 15)\n",
      "Accumulated lines proccesed: 8000000 ( Number of chunks: 16)\n",
      "Accumulated lines proccesed: 8500000 ( Number of chunks: 17)\n",
      "Accumulated lines proccesed: 9000000 ( Number of chunks: 18)\n",
      "Accumulated lines proccesed: 9500000 ( Number of chunks: 19)\n",
      "Accumulated lines proccesed: 10000000 ( Number of chunks: 20)\n",
      "Accumulated lines proccesed: 10000010 ( Number of chunks: 21)\n"
     ]
    }
   ],
   "source": [
    "df_ini = pd.DataFrame() # Initialisation empty dataframe\n",
    "\n",
    "n_chunks = 0 # Initialisation counter of chunks\n",
    "\n",
    "rows = 0 # Initialisation counter of rows\n",
    "\n",
    "for chunk in pd.read_csv(\"bookings.csv.bz2\", compression='bz2', sep = '^', header = 0,names = fixed_columns,chunksize = 500000, low_memory = False):\n",
    "    \n",
    "    rows += len(chunk) # Adding up the number of lines of the chunktest['pax'] = test['pax'].fillna(0) # replacing Nan values from the column pax by 0\n",
    "    \n",
    "    n_chunks += 1 # Adding up a new chunk\n",
    "    \n",
    "    chunk = chunk[chunk['pax'] > 0 ] # Selection only the rows where it's indicated at least one passenger\n",
    "    \n",
    "    chunk['Counter'] = 1\n",
    "    \n",
    "    chunk['cre_date'] = pd.to_datetime(chunk['cre_date'], errors = 'coerce').dt.date.apply(str)\n",
    "    chunk['arr_port'] = chunk['arr_port'].str.strip()\n",
    "    chunk['dep_port'] = chunk['dep_port'].str.strip()\n",
    "    \n",
    "    chunk['CommonKey'] = chunk['cre_date'] + ' ' + chunk['dep_port'] + ' ' + chunk['arr_port']\n",
    "\n",
    "    arr_group = chunk.groupby(['CommonKey'])['Counter'].agg('sum').reset_index() # Group sum of passenger by arr_port\n",
    "\n",
    "    df_ini = df_ini.append(arr_group) # Adding in the dataset retrieved from the current chunk to the accumulated one.\n",
    "    \n",
    "    df_bookings_ini = df_ini.groupby(['CommonKey'])['Counter'].agg('sum').reset_index()# Group the accumulated results by arr_group\n",
    "        \n",
    "    print('Accumulated lines proccesed: ' + str(rows) + ' ( Number of chunks: '+ str(n_chunks) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommonKey</th>\n",
       "      <th>Counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-03-01 CDG WNZ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-03-01 LIS DKR</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-28 BKK CNX</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-28 SYD LHR</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05 LOS AMS</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CommonKey  Counter\n",
       "0  2011-03-01 CDG WNZ       10\n",
       "1  2011-03-01 LIS DKR       10\n",
       "2  2011-06-28 BKK CNX       10\n",
       "3  2011-06-28 SYD LHR       10\n",
       "4  2011-09-05 LOS AMS       30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bookings_ini.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated lines proccesed: 500000 ( Number of chunks: 1)\n",
      "Accumulated lines proccesed: 1000000 ( Number of chunks: 2)\n",
      "Accumulated lines proccesed: 1500000 ( Number of chunks: 3)\n",
      "Accumulated lines proccesed: 2000000 ( Number of chunks: 4)\n",
      "Accumulated lines proccesed: 2500000 ( Number of chunks: 5)\n",
      "Accumulated lines proccesed: 3000000 ( Number of chunks: 6)\n",
      "Accumulated lines proccesed: 3500000 ( Number of chunks: 7)\n",
      "Accumulated lines proccesed: 4000000 ( Number of chunks: 8)\n",
      "Accumulated lines proccesed: 4500000 ( Number of chunks: 9)\n",
      "Accumulated lines proccesed: 5000000 ( Number of chunks: 10)\n",
      "Accumulated lines proccesed: 5500000 ( Number of chunks: 11)\n",
      "Accumulated lines proccesed: 6000000 ( Number of chunks: 12)\n",
      "Accumulated lines proccesed: 6500000 ( Number of chunks: 13)\n",
      "Accumulated lines proccesed: 7000000 ( Number of chunks: 14)\n",
      "Accumulated lines proccesed: 7500000 ( Number of chunks: 15)\n",
      "Accumulated lines proccesed: 8000000 ( Number of chunks: 16)\n",
      "Accumulated lines proccesed: 8500000 ( Number of chunks: 17)\n",
      "Accumulated lines proccesed: 9000000 ( Number of chunks: 18)\n",
      "Accumulated lines proccesed: 9500000 ( Number of chunks: 19)\n",
      "Accumulated lines proccesed: 10000000 ( Number of chunks: 20)\n",
      "Accumulated lines proccesed: 10500000 ( Number of chunks: 21)\n",
      "Accumulated lines proccesed: 11000000 ( Number of chunks: 22)\n",
      "Accumulated lines proccesed: 11500000 ( Number of chunks: 23)\n",
      "Accumulated lines proccesed: 12000000 ( Number of chunks: 24)\n",
      "Accumulated lines proccesed: 12500000 ( Number of chunks: 25)\n",
      "Accumulated lines proccesed: 13000000 ( Number of chunks: 26)\n"
     ]
    }
   ],
   "source": [
    "# Initiating items\n",
    "\n",
    "df_searches_ini = pd.DataFrame()\n",
    "\n",
    "n_chunks = 0\n",
    "\n",
    "rows = 0\n",
    "    \n",
    "# Importation\n",
    "\n",
    "for chunk in pd.read_csv(\"searches.csv.bz2\",compression='bz2',sep = '^',chunksize = 500000, low_memory = False):\n",
    "    \n",
    "    #Counting rows and chunks \n",
    "    \n",
    "    rows += len(chunk)\n",
    "    \n",
    "    n_chunks += 1\n",
    "    \n",
    "    # Creating the common key\n",
    "        \n",
    "    chunk['Date'] = pd.to_datetime(chunk['Date'], errors = 'coerce').dt.date.apply(str)\n",
    "    chunk['Destination'] = chunk['Destination'].str.strip()\n",
    "    chunk['Origin'] = chunk['Origin'].str.strip()\n",
    "    chunk['CommonKey'] = chunk['Date'] + ' ' + chunk['Destination'] + ' ' + chunk['Origin']\n",
    "\n",
    "    # Mergin with the simplified bookings dataset\n",
    "\n",
    "    searches_result = chunk.merge(df_bookings_ini,how = 'left', on =['CommonKey'],indicator = False)\n",
    "    \n",
    "    searches_result['Counter'] = searches_result['Counter'] # Converting the Counter number into 1 when both datasets match up.\n",
    "    \n",
    "    searches_result['Counter'] = searches_result['Counter'].fillna(0) # Replacing Nan by 0.\n",
    "        \n",
    "    \n",
    "    # Aggregating chunks to the database\n",
    "    \n",
    "    df_searches_ini = df_searches_ini.append(searches_result) # I add in the chunk to the dataset which is accumulating all the chunks.\n",
    "    \n",
    "    print('Accumulated lines proccesed: ' + str(rows) + ' ( Number of chunks: '+ str(n_chunks) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_searches_final = df_searches_ini.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exporting_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_searches_final = df_searches_ini.drop(['CommonKey'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_searches_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_searches_final.to_csv('DS_Challenge_Exercise4.csv.bz2', sep = '^', compression ='bz2',index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
