{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the library pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   act_date             10000 non-null  object\n",
      " 1   source               10000 non-null  object\n",
      " 2   pos_ctry             10000 non-null  object\n",
      " 3   pos_iata             10000 non-null  object\n",
      " 4   pos_oid              10000 non-null  object\n",
      " 5   rloc                 10000 non-null  object\n",
      " 6   cre_date             10000 non-null  object\n",
      " 7   duration             10000 non-null  int64 \n",
      " 8   distance             10000 non-null  int64 \n",
      " 9   dep_port             10000 non-null  object\n",
      " 10  dep_city             10000 non-null  object\n",
      " 11  dep_ctry             10000 non-null  object\n",
      " 12  arr_port             10000 non-null  object\n",
      " 13  arr_city             10000 non-null  object\n",
      " 14  arr_ctry             10000 non-null  object\n",
      " 15  lst_port             10000 non-null  object\n",
      " 16  lst_city             10000 non-null  object\n",
      " 17  lst_ctry             10000 non-null  object\n",
      " 18  brd_port             10000 non-null  object\n",
      " 19  brd_city             10000 non-null  object\n",
      " 20  brd_ctry             10000 non-null  object\n",
      " 21  off_port             10000 non-null  object\n",
      " 22  off_city             10000 non-null  object\n",
      " 23  off_ctry             10000 non-null  object\n",
      " 24  mkt_port             10000 non-null  object\n",
      " 25  mkt_city             10000 non-null  object\n",
      " 26  mkt_ctry             10000 non-null  object\n",
      " 27  intl                 10000 non-null  int64 \n",
      " 28  route                10000 non-null  object\n",
      " 29  carrier              10000 non-null  object\n",
      " 30  bkg_class            10000 non-null  object\n",
      " 31  cab_class            10000 non-null  object\n",
      " 32  brd_time             10000 non-null  object\n",
      " 33  off_time             10000 non-null  object\n",
      " 34  pax                  10000 non-null  int64 \n",
      " 35  year                 10000 non-null  int64 \n",
      " 36  month                10000 non-null  int64 \n",
      " 37  oid                  10000 non-null  object\n",
      "dtypes: int64(6), object(32)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#First look at the file (20 rows)\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^')\n",
    "file_head20 =file.head(20)\n",
    "fileinfo = file.info()\n",
    "filecolumns = file.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing process .. first considerations:\n",
    "\n",
    "    a) Turn act_date, cre_date, brd_time and offtime into datetime formats.\n",
    "    b) Eliminate empty spaces in both heads and data itself.\n",
    "    c) Locate NaN, senseless and null values which can distort the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with the headers without empty spaces\n",
    "list_columns = list(filecolumns)\n",
    "fixed_columns = []\n",
    "for col in list_columns:\n",
    "    fixed_columns.append(col.strip())\n",
    "    \n",
    "# Eventually I will use this new headers list to import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_date</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_ctry</th>\n",
       "      <th>pos_iata</th>\n",
       "      <th>pos_oid</th>\n",
       "      <th>rloc</th>\n",
       "      <th>cre_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>...</th>\n",
       "      <th>route</th>\n",
       "      <th>carrier</th>\n",
       "      <th>bkg_class</th>\n",
       "      <th>cab_class</th>\n",
       "      <th>brd_time</th>\n",
       "      <th>off_time</th>\n",
       "      <th>pax</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>oid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>1A</td>\n",
       "      <td>DE</td>\n",
       "      <td>a68dd7ae953c8acfb187a1af2dcbe123</td>\n",
       "      <td>1a11ae49fcbf545fd2afc1a24d88d2b7</td>\n",
       "      <td>ea65900e72d71f4626378e2ebd298267</td>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>1708</td>\n",
       "      <td>0</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>...</td>\n",
       "      <td>LHRZRH</td>\n",
       "      <td>VI</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-03-07 08:50:00</td>\n",
       "      <td>2013-03-07 11:33:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>US</td>\n",
       "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
       "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
       "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>135270</td>\n",
       "      <td>0</td>\n",
       "      <td>SAL</td>\n",
       "      <td>...</td>\n",
       "      <td>SALATLCLT</td>\n",
       "      <td>NV</td>\n",
       "      <td>L</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-04-12 13:04:00</td>\n",
       "      <td>2013-04-12 22:05:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>US</td>\n",
       "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
       "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
       "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>135270</td>\n",
       "      <td>0</td>\n",
       "      <td>SAL</td>\n",
       "      <td>...</td>\n",
       "      <td>CLTATLSAL</td>\n",
       "      <td>NV</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-07-15 07:00:00</td>\n",
       "      <td>2013-07-15 11:34:51</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>AU</td>\n",
       "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
       "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
       "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>30885</td>\n",
       "      <td>0</td>\n",
       "      <td>AKL</td>\n",
       "      <td>...</td>\n",
       "      <td>AKLHKGSVO</td>\n",
       "      <td>XK</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-04-24 23:59:00</td>\n",
       "      <td>2013-04-25 16:06:31</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SYDA82546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>AU</td>\n",
       "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
       "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
       "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>30885</td>\n",
       "      <td>0</td>\n",
       "      <td>AKL</td>\n",
       "      <td>...</td>\n",
       "      <td>SVOHKGAKL</td>\n",
       "      <td>XK</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-05-14 20:15:00</td>\n",
       "      <td>2013-05-16 10:44:50</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SYDA82546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    act_date  source  pos_ctry                          pos_iata  \\\n",
       "0 2013-03-05  1A      DE        a68dd7ae953c8acfb187a1af2dcbe123   \n",
       "1 2013-03-26  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
       "2 2013-03-26  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
       "3 2013-03-26  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
       "4 2013-03-26  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
       "\n",
       "                            pos_oid                              rloc  \\\n",
       "0  1a11ae49fcbf545fd2afc1a24d88d2b7  ea65900e72d71f4626378e2ebd298267   \n",
       "1  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
       "2  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
       "3  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
       "4  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
       "\n",
       "    cre_date  duration  distance  dep_port  ...            route carrier  \\\n",
       "0 2013-02-22      1708         0  ZRH       ...  LHRZRH               VI   \n",
       "1 2013-03-26    135270         0  SAL       ...  SALATLCLT            NV   \n",
       "2 2013-03-26    135270         0  SAL       ...  CLTATLSAL            NV   \n",
       "3 2013-03-26     30885         0  AKL       ...  AKLHKGSVO            XK   \n",
       "4 2013-03-26     30885         0  AKL       ...  SVOHKGAKL            XK   \n",
       "\n",
       "   bkg_class  cab_class            brd_time            off_time pax  year  \\\n",
       "0  T          Y         2013-03-07 08:50:00 2013-03-07 11:33:37  -1  2013   \n",
       "1  L          Y         2013-04-12 13:04:00 2013-04-12 22:05:40   1  2013   \n",
       "2  U          Y         2013-07-15 07:00:00 2013-07-15 11:34:51   1  2013   \n",
       "3  G          Y         2013-04-24 23:59:00 2013-04-25 16:06:31   1  2013   \n",
       "4  G          Y         2013-05-14 20:15:00 2013-05-16 10:44:50   1  2013   \n",
       "\n",
       "  month        oid  \n",
       "0     3  NULL       \n",
       "1     3  NULL       \n",
       "2     3  NULL       \n",
       "3     3  SYDA82546  \n",
       "4     3  SYDA82546  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importation of the file but this time using the proper headers and assigning datetime format to those columns that need it\n",
    "\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^', skiprows = 1, names = fixed_columns, parse_dates = ['act_date','cre_date','brd_time','off_time'])\n",
    "file_head20 =file.head(20)\n",
    "file_head20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#loop to remove white spaces in data columns:\n",
    "\n",
    "for i, r in enumerate(file_head20['arr_port']):  \n",
    "    r1 = r.strip()\n",
    "    file_head20.at[i, 'arr_port'] = r1\n",
    "    \n",
    "# Check that works    \n",
    "for i in file_head20['arr_port']:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LHR', 'CLT', 'SVO', 'LGA', 'SIN', 'TUS'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_arr_port = file_head20['arr_port']\n",
    "column_arr_port.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 repeated values for the column year in the first 100k rows\n",
      "0 repeated values for the column year in the first 100k rows\n",
      "0 repeated values for the column year in the first 100k rows\n",
      "Minimum value in a single row for passengers colums :-80\n",
      "Maximum value in a single row for passengers colums :70\n",
      "Mean for passengers colums :0.50963\n",
      "Median for passengers colums :1.0\n"
     ]
    }
   ],
   "source": [
    "# let's check if there are missing values for the first 100K rows\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 100000, sep = '^', skiprows = 1, names = fixed_columns, parse_dates = ['act_date','cre_date','brd_time','off_time'])\n",
    "print(str(file['year'].isnull().values.sum()) + ' repeated values for the column year in the first 100k rows')\n",
    "print(str(file['pax'].isnull().values.sum()) + ' repeated values for the column year in the first 100k rows')\n",
    "print(str(file['arr_port'].isnull().values.sum())+ ' repeated values for the column year in the first 100k rows')\n",
    "\n",
    "# let's check minimun and maximun of passenger \n",
    "\n",
    "min_pax = file['pax'].min()\n",
    "max_pax = file['pax'].max()\n",
    "mean_pax = file['pax'].mean()\n",
    "median_pax = file['pax'].median()\n",
    "\n",
    "print('Minimum value in a single row for passengers colums :' + str(min_pax))\n",
    "print('Maximum value in a single row for passengers colums :' + str(max_pax))\n",
    "print('Mean for passengers colums :' + str(mean_pax))\n",
    "print('Median for passengers colums :' + str(median_pax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "At the moment I will ignore the min/max values since could be explained by a booking/cancellation of a flight booked by a travel agency.\n",
    "\n",
    "Could be convenient to plot an histogram to see check the frequency of strange values\n",
    "\n",
    "If mean = 51% that means there is a 49% cancellation rate  ??\n",
    "\n",
    "median = 1 --> makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will pick only the information for the exercise 2 ( arr_port, pax, year = 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_port', 'year', 'pax','arr_city']\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^')\n",
    "file2013 = file[file['year'] == 2013]\n",
    "grupo = file2013.groupby('arr_port')['pax'].agg('sum').sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will work by chunks to consolidate the aggregated information I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   act_date             10000 non-null  object\n",
      " 1   source               10000 non-null  object\n",
      " 2   pos_ctry             10000 non-null  object\n",
      " 3   pos_iata             10000 non-null  object\n",
      " 4   pos_oid              10000 non-null  object\n",
      " 5   rloc                 10000 non-null  object\n",
      " 6   cre_date             10000 non-null  object\n",
      " 7   duration             10000 non-null  int64 \n",
      " 8   distance             10000 non-null  int64 \n",
      " 9   dep_port             10000 non-null  object\n",
      " 10  dep_city             10000 non-null  object\n",
      " 11  dep_ctry             10000 non-null  object\n",
      " 12  arr_port             10000 non-null  object\n",
      " 13  arr_city             10000 non-null  object\n",
      " 14  arr_ctry             10000 non-null  object\n",
      " 15  lst_port             10000 non-null  object\n",
      " 16  lst_city             10000 non-null  object\n",
      " 17  lst_ctry             10000 non-null  object\n",
      " 18  brd_port             10000 non-null  object\n",
      " 19  brd_city             10000 non-null  object\n",
      " 20  brd_ctry             10000 non-null  object\n",
      " 21  off_port             10000 non-null  object\n",
      " 22  off_city             10000 non-null  object\n",
      " 23  off_ctry             10000 non-null  object\n",
      " 24  mkt_port             10000 non-null  object\n",
      " 25  mkt_city             10000 non-null  object\n",
      " 26  mkt_ctry             10000 non-null  object\n",
      " 27  intl                 10000 non-null  int64 \n",
      " 28  route                10000 non-null  object\n",
      " 29  carrier              10000 non-null  object\n",
      " 30  bkg_class            10000 non-null  object\n",
      " 31  cab_class            10000 non-null  object\n",
      " 32  brd_time             10000 non-null  object\n",
      " 33  off_time             10000 non-null  object\n",
      " 34  pax                  10000 non-null  int64 \n",
      " 35  year                 10000 non-null  int64 \n",
      " 36  month                10000 non-null  int64 \n",
      " 37  oid                  10000 non-null  object\n",
      "dtypes: int64(6), object(32)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "for gm_chunk in pd.read_csv(\"bookings.csv.bz2\", compression='bz2', sep = '^', chunsize=200000):\n",
    "    gm_chunk = gm_chunk[gm_chunk['year'] == 2013]\n",
    "    gm_chunk = file.groupby(['arr_port', 'arr_city'])['pax'].agg('sum').sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 1)\n",
      "(500000, 1)\n",
      "(500000, 1)\n",
      "(500000, 1)\n",
      "(500000, 1)\n",
      "(500000, 1)\n",
      "(500000, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6ce27fc4a093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgm_chunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bookings.csv.bz2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/bz2.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/_compression.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for gm_chunk in pd.read_csv(\"bookings.csv.bz2\", compression='bz2', sep = '^', usecols = ['source'],chunksize=500000):\n",
    "  print(gm_chunk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
