{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the library pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   act_date             10000 non-null  object\n",
      " 1   source               10000 non-null  object\n",
      " 2   pos_ctry             10000 non-null  object\n",
      " 3   pos_iata             10000 non-null  object\n",
      " 4   pos_oid              10000 non-null  object\n",
      " 5   rloc                 10000 non-null  object\n",
      " 6   cre_date             10000 non-null  object\n",
      " 7   duration             10000 non-null  int64 \n",
      " 8   distance             10000 non-null  int64 \n",
      " 9   dep_port             10000 non-null  object\n",
      " 10  dep_city             10000 non-null  object\n",
      " 11  dep_ctry             10000 non-null  object\n",
      " 12  arr_port             10000 non-null  object\n",
      " 13  arr_city             10000 non-null  object\n",
      " 14  arr_ctry             10000 non-null  object\n",
      " 15  lst_port             10000 non-null  object\n",
      " 16  lst_city             10000 non-null  object\n",
      " 17  lst_ctry             10000 non-null  object\n",
      " 18  brd_port             10000 non-null  object\n",
      " 19  brd_city             10000 non-null  object\n",
      " 20  brd_ctry             10000 non-null  object\n",
      " 21  off_port             10000 non-null  object\n",
      " 22  off_city             10000 non-null  object\n",
      " 23  off_ctry             10000 non-null  object\n",
      " 24  mkt_port             10000 non-null  object\n",
      " 25  mkt_city             10000 non-null  object\n",
      " 26  mkt_ctry             10000 non-null  object\n",
      " 27  intl                 10000 non-null  int64 \n",
      " 28  route                10000 non-null  object\n",
      " 29  carrier              10000 non-null  object\n",
      " 30  bkg_class            10000 non-null  object\n",
      " 31  cab_class            10000 non-null  object\n",
      " 32  brd_time             10000 non-null  object\n",
      " 33  off_time             10000 non-null  object\n",
      " 34  pax                  10000 non-null  int64 \n",
      " 35  year                 10000 non-null  int64 \n",
      " 36  month                10000 non-null  int64 \n",
      " 37  oid                  10000 non-null  object\n",
      "dtypes: int64(6), object(32)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#First look at the file (20 rows)\n",
    "\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^')\n",
    "file_head20 =file.head(20)\n",
    "fileinfo = file.info()\n",
    "filecolumns = file.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing process .. first considerations:\n",
    "\n",
    "    a) Turn act_date, cre_date, brd_time and offtime into datetime formats.\n",
    "    b) Eliminate empty spaces in both heads and data itself.\n",
    "    c) Locate NaN, senseless and null values which can distort the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with the headers without empty spaces\n",
    "\n",
    "list_columns = list(filecolumns)\n",
    "fixed_columns = []\n",
    "for col in list_columns:\n",
    "    fixed_columns.append(col.strip())\n",
    "    \n",
    "# Eventually I will use this new headers list to import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_date</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_ctry</th>\n",
       "      <th>pos_iata</th>\n",
       "      <th>pos_oid</th>\n",
       "      <th>rloc</th>\n",
       "      <th>cre_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>...</th>\n",
       "      <th>route</th>\n",
       "      <th>carrier</th>\n",
       "      <th>bkg_class</th>\n",
       "      <th>cab_class</th>\n",
       "      <th>brd_time</th>\n",
       "      <th>off_time</th>\n",
       "      <th>pax</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>oid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>1A</td>\n",
       "      <td>DE</td>\n",
       "      <td>a68dd7ae953c8acfb187a1af2dcbe123</td>\n",
       "      <td>1a11ae49fcbf545fd2afc1a24d88d2b7</td>\n",
       "      <td>ea65900e72d71f4626378e2ebd298267</td>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>1708</td>\n",
       "      <td>0</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>...</td>\n",
       "      <td>LHRZRH</td>\n",
       "      <td>VI</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-03-07 08:50:00</td>\n",
       "      <td>2013-03-07 11:33:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>US</td>\n",
       "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
       "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
       "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>135270</td>\n",
       "      <td>0</td>\n",
       "      <td>SAL</td>\n",
       "      <td>...</td>\n",
       "      <td>SALATLCLT</td>\n",
       "      <td>NV</td>\n",
       "      <td>L</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-04-12 13:04:00</td>\n",
       "      <td>2013-04-12 22:05:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>US</td>\n",
       "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
       "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
       "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>135270</td>\n",
       "      <td>0</td>\n",
       "      <td>SAL</td>\n",
       "      <td>...</td>\n",
       "      <td>CLTATLSAL</td>\n",
       "      <td>NV</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-07-15 07:00:00</td>\n",
       "      <td>2013-07-15 11:34:51</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>AU</td>\n",
       "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
       "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
       "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>30885</td>\n",
       "      <td>0</td>\n",
       "      <td>AKL</td>\n",
       "      <td>...</td>\n",
       "      <td>AKLHKGSVO</td>\n",
       "      <td>XK</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-04-24 23:59:00</td>\n",
       "      <td>2013-04-25 16:06:31</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SYDA82546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1A</td>\n",
       "      <td>AU</td>\n",
       "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
       "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
       "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>30885</td>\n",
       "      <td>0</td>\n",
       "      <td>AKL</td>\n",
       "      <td>...</td>\n",
       "      <td>SVOHKGAKL</td>\n",
       "      <td>XK</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-05-14 20:15:00</td>\n",
       "      <td>2013-05-16 10:44:50</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SYDA82546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    act_date  source  pos_ctry                          pos_iata  \\\n",
       "0 2013-03-05  1A      DE        a68dd7ae953c8acfb187a1af2dcbe123   \n",
       "1 2013-03-26  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
       "2 2013-03-26  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
       "3 2013-03-26  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
       "4 2013-03-26  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
       "\n",
       "                            pos_oid                              rloc  \\\n",
       "0  1a11ae49fcbf545fd2afc1a24d88d2b7  ea65900e72d71f4626378e2ebd298267   \n",
       "1  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
       "2  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
       "3  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
       "4  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
       "\n",
       "    cre_date  duration  distance  dep_port  ...            route carrier  \\\n",
       "0 2013-02-22      1708         0  ZRH       ...  LHRZRH               VI   \n",
       "1 2013-03-26    135270         0  SAL       ...  SALATLCLT            NV   \n",
       "2 2013-03-26    135270         0  SAL       ...  CLTATLSAL            NV   \n",
       "3 2013-03-26     30885         0  AKL       ...  AKLHKGSVO            XK   \n",
       "4 2013-03-26     30885         0  AKL       ...  SVOHKGAKL            XK   \n",
       "\n",
       "   bkg_class  cab_class            brd_time            off_time pax  year  \\\n",
       "0  T          Y         2013-03-07 08:50:00 2013-03-07 11:33:37  -1  2013   \n",
       "1  L          Y         2013-04-12 13:04:00 2013-04-12 22:05:40   1  2013   \n",
       "2  U          Y         2013-07-15 07:00:00 2013-07-15 11:34:51   1  2013   \n",
       "3  G          Y         2013-04-24 23:59:00 2013-04-25 16:06:31   1  2013   \n",
       "4  G          Y         2013-05-14 20:15:00 2013-05-16 10:44:50   1  2013   \n",
       "\n",
       "  month        oid  \n",
       "0     3  NULL       \n",
       "1     3  NULL       \n",
       "2     3  NULL       \n",
       "3     3  SYDA82546  \n",
       "4     3  SYDA82546  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importation of the file but this time using the proper headers and assigning datetime format to those columns that need it\n",
    "\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 10000, sep = '^', skiprows = 1, names = fixed_columns, parse_dates = ['act_date','cre_date','brd_time','off_time'])\n",
    "file_head20 =file.head(20)\n",
    "file_head20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_port</th>\n",
       "      <th>pax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LHR</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   arr_port  pax\n",
       "0  CLT         2\n",
       "1  LGA         2\n",
       "2  LHR        -1\n",
       "3  SIN         4\n",
       "4  SVO         2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =file_head20.groupby('arr_port')['pax'].agg('sum').reset_index()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   arr_port  6 non-null      object\n",
      " 1   pax       6 non-null      int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#loop to remove white spaces in data columns:\n",
    "\n",
    "for i, r in enumerate(file_head20['arr_port']):  \n",
    "    r1 = r.strip()\n",
    "    file_head20.at[i, 'arr_port'] = r1\n",
    "    \n",
    "# Check that works    \n",
    "for i in file_head20['arr_port']:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LHR', 'CLT', 'SVO', 'LGA', 'SIN', 'TUS'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_arr_port = file_head20['arr_port']\n",
    "column_arr_port.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 repeated values for the column year in the first 100k rows\n",
      "0 repeated values for the column passengers in the first 100k rows\n",
      "0 repeated values for the column arr_port in the first 100k rows\n",
      "Minimum value in a single row for passengers colums :-80\n",
      "Maximum value in a single row for passengers colums :70\n",
      "Median for passengers colums :1.0\n"
     ]
    }
   ],
   "source": [
    "# let's check if there are missing values for the first 100K rows\n",
    "\n",
    "file = pd.read_csv(\"bookings.csv.bz2\", compression='bz2', nrows = 100000, sep = '^', skiprows = 1, names = fixed_columns, parse_dates = ['act_date','cre_date','brd_time','off_time'])\n",
    "print(str(file['year'].isnull().values.sum()) + ' repeated values for the column year in the first 100k rows')\n",
    "print(str(file['pax'].isnull().values.sum()) + ' repeated values for the column passengers in the first 100k rows')\n",
    "print(str(file['arr_port'].isnull().values.sum())+ ' repeated values for the column arr_port in the first 100k rows')\n",
    "\n",
    "# let's check minimun and maximun of passenger \n",
    "\n",
    "min_pax = file['pax'].min()\n",
    "max_pax = file['pax'].max()\n",
    "median_pax = file['pax'].median()\n",
    "\n",
    "print('Minimum value in a single row for passengers colums :' + str(min_pax))\n",
    "print('Maximum value in a single row for passengers colums :' + str(max_pax))\n",
    "print('Median for passengers colums :' + str(median_pax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "At the moment I will ignore the min/max values since could be explained by a booking/cancellation of a flight booked by a travel agency.\n",
    "\n",
    "Could be convenient to plot an histogram to see check the frequency of strange values\n",
    "\n",
    "median = 1 --> makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will work by chunks to consolidate the aggregated information I need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated lines proccesed: 200000 ( Number of chunks: 1)\n",
      "Accumulated lines proccesed: 400000 ( Number of chunks: 2)\n",
      "Accumulated lines proccesed: 600000 ( Number of chunks: 3)\n",
      "Accumulated lines proccesed: 800000 ( Number of chunks: 4)\n",
      "Accumulated lines proccesed: 1000000 ( Number of chunks: 5)\n",
      "Accumulated lines proccesed: 1200000 ( Number of chunks: 6)\n",
      "Accumulated lines proccesed: 1400000 ( Number of chunks: 7)\n",
      "Accumulated lines proccesed: 1600000 ( Number of chunks: 8)\n",
      "Accumulated lines proccesed: 1800000 ( Number of chunks: 9)\n",
      "Accumulated lines proccesed: 2000000 ( Number of chunks: 10)\n",
      "Accumulated lines proccesed: 2200000 ( Number of chunks: 11)\n",
      "Accumulated lines proccesed: 2400000 ( Number of chunks: 12)\n",
      "Accumulated lines proccesed: 2600000 ( Number of chunks: 13)\n",
      "Accumulated lines proccesed: 2800000 ( Number of chunks: 14)\n",
      "Accumulated lines proccesed: 3000000 ( Number of chunks: 15)\n",
      "Accumulated lines proccesed: 3200000 ( Number of chunks: 16)\n",
      "Accumulated lines proccesed: 3400000 ( Number of chunks: 17)\n",
      "Accumulated lines proccesed: 3600000 ( Number of chunks: 18)\n",
      "Accumulated lines proccesed: 3800000 ( Number of chunks: 19)\n",
      "Accumulated lines proccesed: 4000000 ( Number of chunks: 20)\n",
      "Accumulated lines proccesed: 4200000 ( Number of chunks: 21)\n",
      "Accumulated lines proccesed: 4400000 ( Number of chunks: 22)\n",
      "Accumulated lines proccesed: 4600000 ( Number of chunks: 23)\n",
      "Accumulated lines proccesed: 4800000 ( Number of chunks: 24)\n",
      "Accumulated lines proccesed: 5000000 ( Number of chunks: 25)\n",
      "Accumulated lines proccesed: 5199999 ( Number of chunks: 26)\n",
      "Accumulated lines proccesed: 5399999 ( Number of chunks: 27)\n",
      "Accumulated lines proccesed: 5599999 ( Number of chunks: 28)\n",
      "Accumulated lines proccesed: 5799999 ( Number of chunks: 29)\n",
      "Accumulated lines proccesed: 5999999 ( Number of chunks: 30)\n",
      "Accumulated lines proccesed: 6199999 ( Number of chunks: 31)\n",
      "Accumulated lines proccesed: 6399999 ( Number of chunks: 32)\n",
      "Accumulated lines proccesed: 6599999 ( Number of chunks: 33)\n",
      "Accumulated lines proccesed: 6799999 ( Number of chunks: 34)\n",
      "Accumulated lines proccesed: 6999999 ( Number of chunks: 35)\n",
      "Accumulated lines proccesed: 7199999 ( Number of chunks: 36)\n",
      "Accumulated lines proccesed: 7399999 ( Number of chunks: 37)\n",
      "Accumulated lines proccesed: 7599999 ( Number of chunks: 38)\n",
      "Accumulated lines proccesed: 7799999 ( Number of chunks: 39)\n",
      "Accumulated lines proccesed: 7999999 ( Number of chunks: 40)\n",
      "Accumulated lines proccesed: 8199999 ( Number of chunks: 41)\n",
      "Accumulated lines proccesed: 8399999 ( Number of chunks: 42)\n",
      "Accumulated lines proccesed: 8599999 ( Number of chunks: 43)\n",
      "Accumulated lines proccesed: 8799999 ( Number of chunks: 44)\n",
      "Accumulated lines proccesed: 8999999 ( Number of chunks: 45)\n",
      "Accumulated lines proccesed: 9199999 ( Number of chunks: 46)\n",
      "Accumulated lines proccesed: 9399999 ( Number of chunks: 47)\n",
      "Accumulated lines proccesed: 9599999 ( Number of chunks: 48)\n",
      "Accumulated lines proccesed: 9799999 ( Number of chunks: 49)\n",
      "Accumulated lines proccesed: 9999999 ( Number of chunks: 50)\n",
      "Accumulated lines proccesed: 10000009 ( Number of chunks: 51)\n"
     ]
    }
   ],
   "source": [
    "df_ini = pd.DataFrame()\n",
    "\n",
    "n_chunks = 0 # Initalization of number of chunks\n",
    "\n",
    "rows = 0 # Initalization of number of rows\n",
    "\n",
    "for test in pd.read_csv(\"bookings.csv.bz2\", compression='bz2', sep = '^', skiprows = 1, names = fixed_columns, usecols = ['arr_port', 'year', 'pax'],chunksize = 200000):\n",
    "\n",
    "    test = test[test['year'] == 2013] # filter the chunk by the year 2013\n",
    "    \n",
    "    test['pax'] = test['pax'].fillna(0) # replacing Nan from the column pax by 0\n",
    "\n",
    "    arr_group = test.groupby('arr_port')['pax'].agg('sum').reset_index() # Group sum of passenger by arr_port\n",
    "\n",
    "    for i, r in enumerate(arr_group['arr_port']):  # Eliminate white spaces from the column arr_port\n",
    "        \n",
    "        r1 = r.strip()\n",
    "        arr_group.at[i, 'arr_port'] = r1\n",
    "    \n",
    "    n_chunks += 1 # Adding up a new chunk\n",
    "    \n",
    "    rows += len(test) # Adding up the number of lines of the chunk\n",
    "    \n",
    "    df_ini = df_ini.append(arr_group) # Adding in the dataset retrieved from the current chunk to the accumulated one.\n",
    "    \n",
    "    df_ini = df_ini.groupby('arr_port')['pax'].agg('sum').reset_index()# Group the accumulated results by arr_group\n",
    "    \n",
    "    print('Accumulated lines proccesed: ' + str(rows) + ' ( Number of chunks: '+ str(n_chunks) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_port</th>\n",
       "      <th>pax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>LHR</td>\n",
       "      <td>88,809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>MCO</td>\n",
       "      <td>70,930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>LAX</td>\n",
       "      <td>70,530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>LAS</td>\n",
       "      <td>69,630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>JFK</td>\n",
       "      <td>66,270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>CDG</td>\n",
       "      <td>64,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>BKK</td>\n",
       "      <td>59,460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>MIA</td>\n",
       "      <td>58,150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>SFO</td>\n",
       "      <td>58,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>DXB</td>\n",
       "      <td>55,590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_port    pax\n",
       "1088      LHR 88,809\n",
       "1190      MCO 70,930\n",
       "1050      LAX 70,530\n",
       "1047      LAS 69,630\n",
       "886       JFK 66,270\n",
       "315       CDG 64,490\n",
       "216       BKK 59,460\n",
       "1228      MIA 58,150\n",
       "1719      SFO 58,000\n",
       "517       DXB 55,590"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.0f}'.format # before displaying the result I change how the float numbers must be shown\n",
    "\n",
    "top_10 = df_ini.sort_values(by='pax', ascending=False, na_position='first').head(10) # Sorting and selecting the top 10 airports\n",
    "\n",
    "top_10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1 = 10.000.010 rows |\n",
    "Exercise 2 = object top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
